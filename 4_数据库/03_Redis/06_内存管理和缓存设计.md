# 内存管理

Redis主要通过控制内存上线和回收策略实现内存管理

## 设置内存上限

Redis使用maxmemory参数限制最大可用内存。 限制内存的目的主要有：

* 用于缓存场景， 当超出内存上限maxmemory时使用LRU等删除策略释放空间。
* 防止所用内存超过服务器物理内存

**注意**： maxmemory限制的是Redis实际使用的内存量， 也就是used_memory统计项对应的内存。 由于内存碎片率的存在， 实际消耗的内存可能会比maxmemory设置的更大， 实际使用时要小心这部分内存溢出

Redis的内存上限可以通过config set maxmemory进行动态修改， 即修改最大可用内存

通过动态修改maxmemory， 可以实现在当前服务器下动态伸缩Redis内存的目的

## 内存回收策略

Redis内存回收机制主要体现在以下两个方面：

* 删除到达过期时间的策略
* 内存使用达到maxmemeory上限时触发内存溢出控制策略

### 删除过期对象

Redis所有的键都可以设置过期属性， 内部保存在过期字典中。 由于进程内保存大量的键， 维护每个键精准的过期删除机制会导致消耗大量的CPU， 对于单线程的Redis来说成本过高， 因此Redis采用惰性删除和定时任务删除机制实现过期键的内存回收。

* 惰性删除:不主动检测键是否过期，只有当客户端读取带有超时属性的键时，检查取得的键是否过期，如果过期，就执行删除操作并返回空。

  分析：这种策略可以有效节省CPU成本，不需要单独维护TTL链表来处理过期键的删除。但是单独使用会存在内存泄漏的问题，过期键一直没有访问将无法得到及时删除， 从而导致内存不能及时释放。

* 定时任务删除：Redis内部维护一个定时任务， 默认每秒运行10次（通过配置控制） 。 定时任务中删除过期键逻辑采用了自适应算法， 根据键的过期比例、 使用快慢两种速率模式回收键，流程如下：
  * 定时任务在每个数据库空间随机检查20个键， 当发现过期时删除对应的键
  * 如果超过检查数25%的键过期， 循环执行回收逻辑直到不足25%或运行超时为止， 慢模式下超时时间为25毫秒
  * 如果之前回收键逻辑超时， 则在Redis触发内部事件之前再次以快模式运行回收过期键任务， 快模式下超时时间为1毫秒且2秒内只能运行1次
  * 快慢两种模式内部删除逻辑相同， 只是执行的超时时间不同

### 内存溢出控制策略

当Redis数据内存达到 `maxmemory `上限时，便会触发redis的内存淘汰策略

内存淘汰策略可以通过maxmemory-policy进行配置，目前Redis提供了以下策略：

* noeviction，（默认策略）不会淘汰任何数据，当使用的内存空间超过 maxmemory 值时，再有写请求来时返回错误。

* volatile-lru，针对设置了过期时间的key，根据LRU算法进行淘汰。
* allkeys-lru，针对所有key使用LRU算法进行淘汰。
* volatile-random，从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。
* allkeys-random，针对所有的key使用随机淘汰机制进行淘汰。
* volatile-ttl，针对设置了过期时间的key，越早过期的越先被淘汰。
* volatile-lfu，针对设置了过期时间的key，使用lfu算法进行淘汰。
* allkeys-lfu，针对所有key使用lfu算法进行淘汰。

内存溢出控制策略可以采用`config set maxmemory-policy{policy}`动态配置。 

当Redis因为内存溢出删除键时， 可以通过执行`info stats`命令查看evicted_keys指标找出当前Redis服务器已剔除的键数量  

当Redis一直工作在内存溢出（used_memory>maxmemory） 的状态下且设置非noeviction策略时， 会频繁地触发回收内存的操作， 影响Redis服务器的性能,，因为内存淘汰有查找可回收的键和删除键的开销。

#### LRU

Least Recently Used 最近很少使用,也可以理解成最久没有使用

也就是说当内存不够的时候，每次添加一条数据，都需要抛弃一条最久时间没有使用的旧数据

LRU 是基于链表结构实现的，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要进行内存淘汰时，只需要删除链表尾部的元素即可

Redis并没有使用标准的LRU实现方法作为LRU淘汰策略的实现方式，这是因为：  

- 要实现LRU，需要将所有数据维护一个链表，这就需额外内存空间来保存链表

- 每当有新数据插入或现有数据被再次访问，都要调整链表中节点的位置，尤其是频繁的操作将会造成巨大的开销

  为了解决这一问题，Redis使用了近似的LRU策略进行了优化，平衡了时间与空间的效率。

#### 近似LRU

 近似LRU在执行时，会随机抽取N个key，找出其中最久未被访问的key（通过redisObject中的lru字段计算得出），然后删除这个key。然后再判当前内存是超过限制，如仍超标则继续上述过程。

 随机抽取的个数N可以通过redis.conf的配置进行修改，默认为5。

#### LFU

Least Frequently Used  最近最少使用

根据key最近被访问的频率进行淘汰，比较少访问的key优先淘汰，反之则保留

相比LRU算法,LFU增加了访问频率的这样一个维度来统计数据的热点情况

LFU主要使用了两个双向链表去形成一个二维的双向链表，一个用来保存访问频率，另一个用来访问频率相同的所有元素，其内部按照访问时间排序。

#### 淘汰策略的选择

* 如果数据呈现幂等分布(即部分数据访问频率较高而其余部分访问频率较低)，建议使用 allkeys-lru或allkeys-lfu。
* 如果数据呈现平等分布(即所有数据访问概率大致相等)，建议使用 allkeys-random。
* 如果需要通过设置不同的ttls来确定数据过期的顺序，建议使用volatile-ttl。
* 如果你想让一些数据长期保存，而一些数据可以消除，建议使用volatile-lru或volatile-random。



# 缓存设计

缓存能够有效地加速应用的读写速度， 同时也可以降低后端负载，但是也会带来一些问题

## 缓存读写策略

在没有缓存的应用中，客户端直接读写数据库数据。加入缓存后，客户端如何读写数据就分为几种不同的设计策略。

### 旁路缓存模式

旁路缓存模式是我们最常用的缓存设计模式，适合读请求比较多的场景，在这种模式下，服务端需要同时维护`DB`和`cache`的数据

接下来我们看这种模式下应用如何读写数据：

* 写：
  * 先更新DB
  * 再直接删除缓存中的cache
* 读：
  * 首先从cache中读取数据，读取到就直接返回
  * 读取不到(缓存未命中)就从db中读取数据返回
  * 再把数据存放到cache中

在旁路缓存模式下，通过写线程删除cache中数据，由读线程存放cache数据来保证数据库与缓存的一致性，至于为什么是删除cache中数据而不是更新cache数据，为什么先更新DB而不是先删除cache，在后续的数据一致性会介绍。

旁路缓存模式有如下缺陷：

* 首次请求的数据一定不再cache中

  * 解决方案：将热点数据提前放入cache中

* 写操作频繁的情况下导致cache中数据被频繁删除，从而影响缓存命中率

  解决方案：

  * 在强一致性场景下：可以更新DB的同时同样更新cache，但是需要加上一个分布式锁来保证线程安全和数据一致性
  * 在弱一致性场景下：更新DB的同时同样更新cache，但是给缓存加一个较短的过期时间，这样保证即使因为写覆盖导致数据不一致也只是不一致一小段时间。

### 读写穿透模式

读写穿透中服务端把cache视为主要数据存储，从中读取数据并将数据写入其中，而cache服务负责将数据读取和写入db，从而减轻了应用程序的负担。

这种模式在开发过程中很少见，我们常用的Redis并没有提供cache将数据写入db的功能。

读写穿透模式下，应用读写数据的策略如下：

* 写：
  * 先查cache，若cache中不存在，直接更新db
  * cache中存在，则先更新cache，然后cache服务自己更新db
* 读：
  * 从cache中读取数据，读取到就直接返回
  * 如果读取不到，cache访问db加载数据，写入cache后返回

### 异步缓存写入

异步缓存写入和读写穿透很相似，两者都是由`cache`服务来负责`cache`和`DB`的读写。

两者最大的不同点就是：读写穿透是同步更新`DB`和`cache`，而异步缓存写入则是只更新`cache`，不直接更新`DB`，而是改为异步批量的方式更新`DB`。

很明显，这种方式对数据一致性带来了更大的挑战，比如`cache`数据可能还没异步更新`DB`，`cache`服务可能就挂了。

这种策略在我们平时开发过程中也非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、`MySQL`的`InnoDB Buffer Pool`机制都用到了这种策略。

## 缓存一致性

redis作为缓存时，需要保证缓存数据与数据库数据的一致性

即数据库数据和缓存数据在同一时间是一致的

针对不同程度的一致性，我们可以划分：

* 强一致性：数据库更新操作与缓存更新操作是原子性的，缓存与数据库的数据在任何时刻都是一致的
* 弱一致性：当数据更新后，缓存中的数据可能是更新前的值，也可能是更新后的值
* 最终一致性：一种特殊的弱一致性，在一定时间后，数据会达到一致的状态。最终一致性是弱一致性的理想状态，也是分布式系统的数据一致性解决方案上比较推崇的。

要保证一致性，就必须在数据库修改数据的同时，修改缓存的数据，而修改缓存可以是直接更新缓存，也可以是删除缓存数据，当下一次请求数据时，再访问数据库，将新数据加载入缓存，而修改或删除缓存的时机可以是更新数据库前，也可以是更新数据库后，这样组合后有四种方案来保证数据的一致性，

但在并发情况的某些场景下，仍然无法保证数据的一致性，我们来分析具体的情况：

### 先更新缓存，再更新数据库

**双写场景**：两个线程同时更新同一个数据，会出现一个线程覆盖另一个线程对数据库的更新操作，造成数据库与缓存的不一致

![先更新缓存再更新数据库的双写场景](https://gitee.com/wangziming707/note-pic/raw/master/img/%E5%85%88%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%E5%86%8D%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%8F%8C%E5%86%99%E5%9C%BA%E6%99%AF.png)

**读写场景**：如果读线程的缓存未命中，那么仍然要访问数据库，同样会出现更新覆盖的情况，造成数据库和缓存的不一致

![先更新缓存再更新数据库读写场景](https://gitee.com/wangziming707/note-pic/raw/master/img/%E5%85%88%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%E5%86%8D%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E5%9C%BA%E6%99%AF.png)



### 先更新数据库，再更新缓存

**双写场景**：会出现一个线程覆盖另一个线程对缓存数据的更新操作，造成数据库和缓存的不一致

![先更新数据库再更新缓存双写场景](https://gitee.com/wangziming707/note-pic/raw/master/img/%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%8D%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%E5%8F%8C%E5%86%99%E5%9C%BA%E6%99%AF.png)

**读写场景**：如果读线程的缓存未命中，那么同样会出现数据不一致的情况

![先更新数据库再更新缓存读写场景](https://gitee.com/wangziming707/note-pic/raw/master/img/%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%8D%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E5%9C%BA%E6%99%AF.png)

### 先删除缓存，再更新数据库

**双写场景**：都会删除cache数据，由后续的读线程更新数据，不会出现不一致的情况

**读写场景**：在读线程缓存未命中时，有可能出现数据不一致的情况

![先删除缓存再更新数据库读写场景](https://gitee.com/wangziming707/note-pic/raw/master/img/%E5%85%88%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E5%86%8D%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E5%9C%BA%E6%99%AF.png)

### 先更新数据库，再删除缓存

**双写场景**：都会删除cache数据，由后续的读线程更新数据，不会出现不一致的情况

**读写场景**：在写线程更新db操作和删除cache操作之间，读线程会读到旧数据，但最终数据会一致

![先更新数据库再删除缓存读写场景](https://gitee.com/wangziming707/note-pic/raw/master/img/%E5%85%88%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%8D%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E8%AF%BB%E5%86%99%E5%9C%BA%E6%99%AF.png)

### 延迟双删

分析上面的结果，我们得到，更新缓存无法保证读写和双写的数据一致性，先删除缓存只能保证双写的数据一致性，读写场景在缓存为命中时仍然有可能出现数据不一致的情况

可以改进先删除缓存，再更新数据库的策略：

**延迟双删**：先删除缓存，再更新数据库，延迟一段时间后再删除缓存

这里延迟一段时间是用来保证数据库更新完成，此时再删除缓存会将不一致的数据删除，保证了最终一致性

## 缓存穿透

缓存穿透指请求访问一个不存在的数据，缓存就一定不会命中，这样的请求就会全部打向数据库。

如果发生大量缓存穿透，就会导致数据库负载过高宕机，这通常发生在恶意攻击中。

如果有大量访问不存在的数据的请求，这些请求就会打向数据库，导致数据库崩溃

解决方案：

* 接口校验：对接口的请求参数进行校验，只有合格的请求才会访问数据

* 缓存空值：当数据库返回空时，将这些空值对应的key缓存到Redis中，并设置过期时间，这样下一次相同的请求来时就不会打到数据库中(仍然不安全，比如有大量随机的请求)

* 布隆过滤器：

  * 类似哈希表，但保存的是二进制向量，并且有多个哈希函数，在时间和空间上都很有优势，常用来判断是否存在和去重

    对于一个值：

    只有对应的所有哈希值对应的二进制向量点都存在在布隆过滤器中时，该值才有可能存在(会发生误判)

    只要有一个哈希值不在布隆过滤器中，那么该值一定不在布隆过滤器中

    * 优势：占用空间极小，插入和查询速度极快
    * 缺点：误算率随着元素的增加而增加，一般情况下无法删除元素

  * 维护一个布隆过滤器，该数据结构保存数据库中所有存在的数据(Guava框架 或者 Redisson)

    当缓存未命中时，Redis会先访问布隆过滤器，只有在布隆过滤器中存在该key，才会继续访问数据库

    这样能保证所有未命中但数据库中存在的数据访问数据库，但会有很少一部分访问了数据库中没有的数据的请求访问到数据库，但这样的请求是很少的

## 缓存击穿

当某个热点数据key在Redis中过期时，有大量该key的并发请求，在某个线程首先将数据库中数据加载到Redis之前，这些请求会一起访问数据库，导致数据库压力过大

解决方案：

* 互斥锁：当缓存未命中时，对接下来的操作进行同步，并再查询一次缓存，若此时再未命中，才会查询数据库，这样能保证当热点key失效时，只有一个线程能访问到数据库

* 自动续期，设置定时任务，在热点数据过期前自动更新缓存
* 缓存永不失效：对于几乎不会变动的热点数据，可以将其设置为永不失效

## 缓存雪崩

大量热点数据同时过期，造成大量请求直接访问数据库，或者缓存服务直接宕机导致所有请求直接访问数据库，造成雪崩

解决方案：

* 优化缓存过期时间，过期时间加上随机值
* 搭建集群，保证Redis的高可用
* 限流和降级组件





