# 过期策略

如果设置了键的生存时间，redis会在指定时间删除过期键

有三种过期策略：

* 定时删除:在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。
    * 优点：对内存友好，证过期的键会尽可能快地被删除，释放所占内存
    * 缺点：对cpu最不友好：生成定时器删除键会消耗cpu资源

* 惰性删除:放任键的过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。
    * 优点：对cpu最友好，既不需要创建大量定时器，也不需要定时扫描资源
    * 缺点：对内存最不友好，如果有大量过期的键没有被访问过，那么这些键就会一直保存在内存中，消耗大量的内存
* 定期删除:每隔一段时间，程序就对数据库进行一次检查，删除里面过期的键。至于要删除多少过期键，以及要检查多少个数据库，则有算法决定。
    * 优点：相较于以上两种方案，兼顾了cpu和内存
    * 缺点：难以确定删除操作执行的时长和频率

Redis采用的是惰性删除和定期删除两种策略：通过配好使用这两种策略，服务器可以很好地在合理使用cpu时间和避免浪费内存空间之间取得平衡。

## 惰性删除实现

过期键的惰性删除删除策略由db.c/expireIfNeeded函数实现，所有读写数据库的Redis命令在执行之前都会调用expireIfNeed函数对输入键进行检查：

- 如果键已经过期，那么expireIfNeeded函数将键删除
- 如果键未过期，那么expireIfNeeded函数不做操作

## 定期删除实现

过期键的定期删除策略由redis.c/activeExpireCycle函数实现，每当Redis的服务器周期性操作redis.c/serverCron函数执行时，activeExpireCycle函数就会被调用，它在规定时间内，分多次遍历服务器中各个数据库。

Redis 默认每秒进行 10 次过期扫描，过期扫描不会遍历过期字典中所有的 key, 而是采用了一种简单的贪心策略，步骤如下。

* 从过期字典中随机选出 20个 key。
* 删除这 20 个 key 中已经过期的 key。
* 如果过期的 key的比例超过 1/4，那就重复第一个步骤。

同时，为了保证过期扫描不会出现循环过度，导致结程卡死的现象，算法还增加了扫描时间的上限，默认不会超过 25ms。

所以如果有大量key在同一时间过期，会导致activeExpireCycle函数循环多次，导致请求卡顿或超时



# 内存淘汰机制

在配置文件redis.conf 中，可以通过参数` maxmemory <bytes>` 来设定最大内存，当数据内存达到 `maxmemory `时，便会触发redis的内存淘汰策略

内存淘汰策略可以通过maxmemory-policy进行配置，目前Redis提供了以下几种（2个LFU的策略是4.0后出现的）：

* volatile-lru，针对设置了过期时间的key，使用lru算法进行淘汰。
* allkeys-lru，针对所有key使用lru算法进行淘汰。
* volatile-lfu，针对设置了过期时间的key，使用lfu算法进行淘汰。
* allkeys-lfu，针对所有key使用lfu算法进行淘汰。
* volatile-random，从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。
* allkeys-random，针对所有的key使用随机淘汰机制进行淘汰。
* volatile-ttl，针对设置了过期时间的key，越早过期的越先被淘汰。
* noeviction，（默认策略）不会淘汰任何数据，当使用的内存空间超过 maxmemory 值时，再有写请求来时返回错误。

volatile-前缀的策略代表从设置了过期时间的key中选择键进行清除

allkeys-开头的策略代表从所有key中选择键进行清除

## LRU

Least Recently Used 最近很少使用,也可以理解成最久没有使用

也就是说当内存不够的时候，每次添加一条数据，都需要抛弃一条最久时间没有使用的旧数据

LRU 是基于链表结构实现的，链表中的元素按照操作顺序从前往后排列，最新操作的键会被移动到表头，当需要进行内存淘汰时，只需要删除链表尾部的元素即可

Redis并没有使用标准的LRU实现方法作为LRU淘汰策略的实现方式，这是因为：  

- 要实现LRU，需要将所有数据维护一个链表，这就需额外内存空间来保存链表
- 每当有新数据插入或现有数据被再次访问，都要调整链表中节点的位置，尤其是频繁的操作将会造成巨大的开销

  为了解决这一问题，Redis使用了近似的LRU策略进行了优化，平衡了时间与空间的效率。

## 近似LRU

 近似LRU在执行时，会随机抽取N个key，找出其中最久未被访问的key（通过redisObject中的lru字段计算得出），然后删除这个key。然后再判当前内存是超过限制，如仍超标则继续上述过程。

 随机抽取的个数N可以通过redis.conf的配置进行修改，默认为5。

## LFU

Least Frequently Used  最近最少使用

根据key最近被访问的频率进行淘汰，比较少访问的key优先淘汰，反之则保留

相比LRU算法,LFU增加了访问频率的这样一个维度来统计数据的热点情况

LFU主要使用了两个双向链表去形成一个二维的双向链表，一个用来保存访问频率，另一个用来访问频率相同的所有元素，其内部按照访问时间排序。

## 淘汰策略的选择

* 如果数据呈现幂等分布(即部分数据访问频率较高而其余部分访问频率较低)，建议使用 allkeys-lru或allkeys-lfu。
* 如果数据呈现平等分布(即所有数据访问概率大致相等)，建议使用 allkeys-random。
* 如果需要通过设置不同的ttls来确定数据过期的顺序，建议使用volatile-ttl。
* 如果你想让一些数据长期保存，而一些数据可以消除，建议使用volatile-lru或volatile-random。









# Redis高可用

Redis 实现高可用有三种部署模式：主从模式，哨兵模式，Cluster模式



## Sentinel

sentinel哨兵提供主从复制模式的故障转移的的自动化处理

### 原理

Redis Sentinel是运行在特殊模式下的Redis服务器

有三个主要任务：

* 监控：Sentinel不断检查主服务器和从服务器是否按照预期正常工作，

    每隔固定时间sentinel会请求主服务器，如果没有收到主服务的正常响应，则报告异常

* 提醒：被监视的Redis出现问题时，Sentinel会通知管理员或其他应用程序

* 自动故障转移：监控的主Redis不能正常工作，Sentinel会开始进行故障迁移操作。

    将一个从服务器升级新的主服务器。让其他从服务器挂到新的主服务器。同时向客户端提供新的主服务器地址

Sentinel分布式系统：

* 如果只有一个Sentinel，那么Sentinel出现问题就无法监控。所以需要多个哨兵，组成Sentinel网络。一个健康的sentinel至少有三个Sentinel应用。彼此在独立的物理机器或虚拟机
* 监控同一个Master的Sentinel会自动连接，组成一个分布式的网络，互相通信并彼此交换关于被监控服务器的信息
* 当一个 Sentinel 认为被监控的服务器已经下线时，它会向网络中的其它 Sentinel 进行确认，判断该服务器是否真的已经下线 
* 如果下线的服务器为主服务器，那么 Sentinel 网络将对下线主服务器进行自动故障转移，通过将下线主服务器的某个从服务器提升为新的主服务器，并让其从服务器转移到新的主服务器下，以此来让系统重新回到正常状态 
* 下线的旧主服务器重新上线，Sentinel 会让它成为从，挂到新的主服务器下 

### 实现

配置sentinel.conf文件：

~~~python
#sentinel自己的接口:
port <port>
#sentinel要监视的master:
sentinel monitor <name> <masterIP> <masterPort> <Quorum>
# quorum 表示投票数，当有超过该数量的哨兵认为服务器已经下线，才会判断下线
~~~

启动sentinel服务器：

~~~python
redis-sentinel sentinel.conf
~~~

## Cluster

Sentinel 集群方案中只有一个主服务器，只提高了redis 的可用性，并没有提高redis 的性能，如果业务对redis性能有高要求，需要搭建多台主服务器，来提高redis性能，这就是cluster集群

为了实现高可用，最好一个集群有3个master节点，每个master节点至少有1个子节

哈希槽：

cluster集群的设计是去中性化的

它引入了哈希槽的概念，Redis集群有16384个哈希槽

在集群中的每个主节点会被分配相等个数的哈希槽

在进行set操作时，每个key会通过 CRC16 算法得出当前key对应的哈希槽，这样就能知道这个key应该去往的master节点

gossip协议：

redis集权通过gossip协议进行通讯，保证所有节点都会知道整个集群完整的信息

# 缓存问题

redis作为缓存可以显著提高数据库的性能，但也带来了许多问题

## 数据一致性

redis作为缓存时，需要保证缓存数据与数据库数据的一致性

即数据库数据和缓存数据在同一时间是一致的

针对不同程度的一致性，我们可以划分：

* 强一致性：数据库更新操作与缓存更新操作是原子性的，缓存与数据库的数据在任何时刻都是一致的，这是最难实现的一致性。
* 弱一致性：当数据更新后，缓存中的数据可能是更新前的值，也可能是更新后的值，因为这种更新是异步的。
* 最终一致性：一种特殊的弱一致性，在一定时间后，数据会达到一致的状态。最终一致性是弱一致性的理想状态，也是分布式系统的数据一致性解决方案上比较推崇的。

要保证一致性，就必须在数据库修改数据的同时，修改缓存的数据，而修改缓存可以是直接更新缓存，也可以是删除缓存数据，当下一次请求数据时，再访问数据库，将新数据加载入缓存，而修改或删除缓存的时机可以是更新数据库前，也可以是更新数据库后，这样组合后有四种方案来保证数据的一致性，

但在并发情况的某些场景下，仍然无法保证数据的一致性，我们来分析具体的情况：

* 先更新缓存，再更新数据库
    * 双写场景：两个线程同时更新同一个数据，会出现一个线程覆盖另一个线程对数据库的更新操作，造成数据库与缓存的不一致

    * 读写场景：如果读线程的缓存未命中，那么仍然要操作数据库，同样会出现更新覆盖的情况，造成数据库和缓存的不一致

* 先更新数据库，再更新缓存
    * 双写场景：会出现一个线程覆盖另一个线程对缓存数据的更新操作，曹成数据库和缓存的不一致
    * 读写场景：如果读线程的缓存未命中，那么同样会出现数据不一致的情况
* 先删除缓存，再更新数据库的
    * 双写场景：数据是一致的
    * 读写场景：在读线程缓存为命中时，有可能出现数据不一致的情况
* 先更新数据库，在删除缓存
    * 双写场景：数据是一致的
    * 读写场景：缓存未命中时，有可能数据会不一致

分析上面的结果，我们得到，更新缓存无法保证读写和双写的数据一致性，删除缓存只能保证双写的数据一致性，读写场景在缓存为命中时仍然有可能出现数据不一致的情况

以上策略都无法保证数据的一致性，所以改进了删除缓存的策略，出现了：

* 延迟双删：先删除缓存，再更新数据库，延迟一段时间后再删除缓存

该方法可以保证最终一致性

## 缓存穿透

查询了缓存和数据库中都不存在的数据，因为缓存中没有，数据库中也没有，因为数据库中没有改数据，所以不会加载到缓存中，所以所有的请求都会打向数据库。

如果有大量访问不存在的数据的请求，这些请求就会打向数据库，导致数据库崩溃

解决方案：

* 前端验证：对接口的请求参数进行校验，只有合格的请求才会被发起(仍然不安全，比如请求并不是通过前端)
* 缓存空值：当数据库返回空时，将这些空值对应的key缓存到Redis中，并设置过期时间，这样下一次相同的请求来时就不会打到数据库中(仍然不安全，比如有大量随机的请求)

* 布隆过滤器：

    * 类似哈希表，但保存的是二进制向量，并且有多个哈希函数，在时间和空间上都很有优势，常用来判断是否存在和去重

        对于一个值：

        只有对应的所有哈希值对应的二进制向量点都存在在布隆过滤器中时，该值才有可能存在(会发生误判)

        只要有一个哈希值不在布隆过滤器中，那么该值一定不在布隆过滤器中

        * 优势：占用空间极小，插入和查询速度极快
        * 缺点：误算率随着元素的增加而增加，一般情况下无法删除元素

    * 维护一个布隆过滤器，该数据结构保存数据库中所有存在的数据(Guava框架 或者 Redisson)

        当缓存未命中时，Redis会先访问布隆过滤器，只有在布隆过滤器中存在该key，才会继续访问数据库

        这样能保证所有未命中但数据库中存在的数据访问数据库，但会有很少一部分访问了数据库中没有的数据的请求访问到数据库，但这样的请求是很少的



## 缓存击穿

当某个热点数据key在Redis中过期时，有大量该key的并发请求，在某个线程首先将数据库中数据加载到Redis之前，这些请求会一起访问数据库，增加数据库压力

解决方案：

* 互斥锁：当缓存未命中时，对接下来的操作进行同步，并再查询一次缓存，若此时再未命中，才会查询数据库，这样能保证当热点key失效时，只有一个线程能访问到数据库

    该方案会降低业务系统的性能

* 设置缓存数据永不过期，(实现：在数据快过期时，使用异步线程刷新数据) 可能会存在数据不一致的情况

* 设置接口限流与熔断，降级。



## 缓存雪崩

大量热点数据同时过期，造成大量请求对不同过期的key进行访问，引起雪崩的现象

解决方案：

* 优化缓存过期时间，过期时间加上随机值
* 搭建集群，保证Redis的高可用
* 加锁同步
* 限流和降级组件

