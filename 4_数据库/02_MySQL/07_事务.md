# 概述

事务(Transaction)是数据库区别于文件系统的重要特性之一。事务会把数据库从一种一致状态转换为另一种一致状态。不会让数据库的最终物理存储处于不一致的状态。

InnoDB存储引擎中的事务完全符合ACID的特性：

* 原子性 atomicity：事务的所有操作在数据库中要么全部正确反映出来，要么完全不反映
* 一致性 consistency：隔离执行事务时，保持数据库的一致性
* 隔离性 isolation：在多个事务并发执行的情况下，保证对任何一对事务$T_i$和$T_j$在$T_i$看来，$T_j$要么已经执行了，要么还没执行，在$T_i$的视角下不存在$T_j$执行中的状态
* 持久性 durability：一个事务成功完成后，它对数据库的改变必须时永久的，即使出现系统故障

## 分类

可以将事务分为以下几种类型：

* 扁平事务
* 带有保存点的扁平事务
* 链事务
* 嵌套事务
* 分布式事务

扁平事务是事务类型中最简单的一种，在实际生产中也是使用最频繁的事务。在扁平事务中，所有操作处于同一层次，由begin 开始，由commit或者rollback结束。其间的操作是原子的，要么都执行，要么都回滚。

某些事务中出现的错误可能不会导致所有的操作都无效，放弃整个事务可能不合要求，并且开销也太大。这时候可以用带保存点的扁平事务。保存点(savepoint)用来通知系统应该记住事务当前的状态，以便发生错误时，事务能够回到保存点当前的状态。使用rollback命令可以指定需要回滚到的保存点位置。

链事务可视为保存点模式的一种变种，带有保存点的扁平事务，其保存点是存放在内存中的，所以当数据库宕机后，所有的保存点就会消失，这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。

链事务的思想是：当提交一个事务时，释放不需要的数据独享，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行一样。

嵌套事务是一个层次结构框架。由一个顶层事务控制各个层次的事务。顶层事务下嵌套的事务称为子事务。嵌套事务的定义如下：

* 嵌套事务由若干事务组成的一颗树，子树既可以是嵌套事务，也可以是扁平事务
* 处在叶节点的事务是扁平事务。
* 位于根节点的事务称为顶层事务。
* 子事务既可以提交也可以回滚。但是它的提交操作并不马上生效，除非其父事务已经提交。
* 树中任意一个事务的回滚会引起它的所有子事务一同回滚，所以子事务没有持久性。

分布式事务通常是在一个分布式环境下运行的扁平事务。

# 事务的实现

事务的隔离性通过之前讲述的锁来实现。原子性、一致性、持久性则通过数据库的redo log 和 undo log 来完成。

## redo

重做日志用来保证实现事务的持久性。它记录了数据库对物理页的修改。

重做日志由两部分组成：一是内存中的redo log buffer，二是磁盘中的redo log file

InnoDB是事务的存储引擎，其通过Force Log at Commit的机制实现事务的持久性。即当事务提交时，必须先将该事务的日志都写入日志文件进行持久化，才能真正完成commit操作。这里的日志指的就是redo log 和undo log。

redo log用来保证事务的持久性，undo log用来帮助事务回滚和实现MVCC的功能。redo log 基本是顺序写的，在数据库运行时不需要对redo log的文件进行读取操作，而undo log是要进行随机读写的。

因为重做日志文件没有打开`O_DIRECT`选项，因此重做日志缓冲会首先写入文件系统缓存。为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重组日志文件后，InnoDB需要调用一次fsync操作，将数据从文件系统缓存同步到真正的物理磁盘文件中。由于fsync的效率取决于磁盘的性能，所以磁盘的性能决定了事务提交的性能，也就是数据库的性能。

InnoDB允许设置非持久性的情况发生，以提高数据库的性能。即当事务提交时，日志不写入重做日志文件，而是等待一个时间周期后再执行`fsync`操作。这能显著提高数据库性能，但是会降低数据库的可用性。

参数`innodb_flush_log_at_trx_commit`用来控制重做日志刷新到磁盘的策略，它有以下几个可选值：

* 1(默认值):表示事务提交时必须调用一次fsync操作
* 0表示事务提交时不进行写入重做日志操作，重做日志从缓冲池的冲刷操作和 fsync操作仅在master thread 的1s一次的循环中进行。
* 2表示事务提交时将重做日志写入重做日志，但仅写入文件系统的缓存中，不进行fsync操作。这个设置下，数据库宕机而操作系统没有宕机时，不会导致事务的丢失。

MySQL数据库还有一种二进制日志(binlog)，用来进行point-in-time的恢复及主从复制环境的建立。从表面上看，redo log 和 binlog都是对数据库操作的日志。但是它们实际上很不同

* redo log是InnoDB存储引擎层的，是物理格式的日志，记录的是对于每个页的修改，重做日志在事务进行中不断被写入
* binlog是MySQL数据库层面的，是逻辑日志，记录的是对应的SQL语句。二进制日志只在事务提交完成后进行一次写入

### log block

在InnoDB中，redo log 是以512字节进行存储的。这意味这重做日志缓存、重做日志文件都是以块(block)的方式进行保存的，称之为redo log block。

若一个页中产生的redo log 大于512字节，则需要分割多个重做日志块进行存储。因为redo log block 大小和磁盘扇区大小一样，都是512字节，因此重做日志的写入可以保证原子性，不需要doublewrite

redo log block 除了日志本身外还有日志快头(log block header)和日志块尾(log block tailer)两部分组成，头占12个字节，尾占8字节，所以每个块实际可用的大小为492字节。其结构如下：

![RedoLogBlockStructure](https://gitee.com/wangziming707/note-pic/raw/master/img/RedoLogBlockStructure.png)

### log group

log group 为重做日志组，其中有多个重做日志文件。InnoDB目前只有一个log group。

log group 是一个逻辑上的概念，并没有一个实际存储的物理文件来表示log group信息。log group由多个redo log file组成，每个log group中的日志文件大小是相同的。

在InnoDB1.2版本之前，重做日志文件的总大小要小于4GB，从InnoDB1.2版本开始，总大小限制为512GB。

重做日志文件中存储的就是 log block。在InnoDB运行过程中，log buffer 根据一定的规则将内存中的log block 刷新到磁盘。具体规则是：

* 事务提交时
* 当log buffer 中有一半的内存空间已被使用时
* log checkpoint时

对于log block的写入追加(append)在redo log file 的最后部分，当一个redo log file被写满时，会写入下一个redo log file，其使用方式为round-robin

### 重做日志格式

InnoDB的存储是基于页的，所以重做日志格式也是基于页的，虽然有着不同的重做日志格式，但是它们有通用的头部格式：

![RedoLogFormat](https://gitee.com/wangziming707/note-pic/raw/master/img/RedoLogFormat.png)

通用的头部格式由以下三部分组成：

* redo_log_type:重做日志类型
* space：表空间ID
* page_no：页的偏移量

之后redo log body的部分，根据重做日志类型的不同，会有不同的存储内容，例如，对于页上记录的插入和删除操作，对应如下格式：

![RedoLogBody](https://gitee.com/wangziming707/note-pic/raw/master/img/RedoLogBody.png)

到InnoDB1.2版本时，一共有51种重做日志类型。后续可能还会增加

### LSN

LSN是Log Sequence Number的缩写，表示日志序列号，在InnoDB中，LSN占8字节，且单调递增。LSN表示的含义有：

* 重做日志写入的总量
* checkpoint的位置
* 页的版本

LSN表示事务写入重做日志的字节的总量。比如当前redo log 的LSN为1000，当一个事务T1写入了100字节的日志，那么LSN就变成了1100。

LSN不仅记录在redo log 中，还存在于每个页中。在每个页的头部，有一个`FIL_PAGE_LSN`记录了该页的LSN。在页中，LSN表示该页最后刷新时LSN的大小。因为重做日志记录的是每个页的日志，因此页中的LSN用来判断页是否需要进行恢复操作。例如页P1的LSN为10000，而数据库启动时，InnoDB检测到写入重做日志中的LSN为13000，那么数据库就需要进行恢复操作，将重做日志应用到P1中。

可以通过命令`show enging innodb status`查看LSN的情况

### 恢复

InnoDB在启动时不管上次数据库运行时是否正常关闭，都会尝试进行恢复操作。因为重做日志记录的是物理日志，因此恢复的速度比逻辑日志，如binlog ，要快很多。并且InnoDB自身对恢复进行了一定程度的优化，比如顺序读取及并行应用重做日志，进一步提高了数据库恢复的速度。

checkpoint表示已经刷新到磁盘上的操作。所以恢复过程中只需要恢复checkpoint开始的日志部分。当数据库在checkpoint为LSN为10000时发生宕机，恢复操作只需要恢复LSN在10000以后的日志。

## undo

undo log 用来帮助事务进行回滚操作。当事务失败，或者执行了rollback语句时，可以利用undo信息将数据恢复到修改前的样子。

undo存放在数据库内部的一个特殊段(segment)中，这个段称为undo段(undo segment)。undo段位于共享表空间中。

undo是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子(比如对于每个insert，回滚时，通过undo日志执行一条相反的delete,对于每个update，回滚会执行一个相反的insert)所以虽然表面上看数据库表恢复成原来的样子了，但是物理存储上的数据结构和页本身可能不会和事务开始时一样了。

将undo日志设计成逻辑的，是因为数据库本身是并发的，可能在同时运行多个并发事务，如果对其中的一个事务的修改直接在物理存储层面回滚，那么可能会覆盖影响其他事务的记录。

除了回滚操作，undo的另一个作用是MVCC，即InnoDB中的MVCC中实现是通过undo来完成的。当事物读取一行记录时，若该记录已经被其他事务占用，当前十五可以通过undo读取之前的行版本信息，以实现非锁定读取。

最后也最为重要的一点，undo log 会产生redo log，也就是undo log的产生操作有对应的redo log，这是因为undo log也需要持久性的保护

### undo 存储管理

#### undo段

InnoDB对undo的管理同样采用段的方式。但是这个段和普通的段有所不同。

首先InnoDB有rollback segment，每个回滚段记录了1024个undo log segment，在每个undo log segment 中进行undo页的申请。共享表空间偏移量为5的页(0,5)记录了所有rollback segment header所在的页，这个页的类型为FIL_PAGE_TYPE_SYS

在InnoDB1.1版本之前，只有一个rollback segment，因此支持同时在线的事务限制为1024.

从InnoDB1.1版本开始，支持最大128个rollback segment，所以支持同时在线的事务限制提高到了128*1024.

InnoDB中的rollback segment存储在共享表空间中，可以通过下面参数对rollback segment进行控制：

* `innodb_undo_directory`:用于设置rollback segment文件所在的路径。这意味这rollback segment可以存在在共享表空间之外的位置，即可以设置为独立表空间。
* `innodb_undo_tablespaces`：用于设置构成rollback segment文件的数量

#### undo log的释放

事务在 undo log segment 分配页并写入 undo log的过程同样需要写入重做日志。当事务提交时，InnoDB做下面的动作：

* 将undo log 放入列表中，供之后的purge 操作
* 判断undo log 所在的页是否可以重用，若可以分配给下个事务使用

事务提交后不能马上删除undo log 和undo log 所在的页。因为可能还有其他事务需要通过undo log 来得到行记录之前的版本。所以事务提交时将undo log 放入一个链表中，由purge线程来决定是否删除undo log和其所在的页。

#### undo页的重用

若为每个事物分配一个单独的undo页会非常浪费空间，因此InnoDB的设计中对undo页是可以重用的。

具体来说，当事务提交时，首先将undo log 放入链表中，然后判断undo页的使用空间是否小于3/4，若是则表示该undo页可以被重用，之后新的undo log记录在当前undo log的后面。

由于存放undo log的列表是以记录进行组织的，而undo页可能存放不同事物的undo log，因此purge操作需要涉及磁盘的离散读取操作，会比较慢。

可以通过`show engine innodb status`来查看链表中undo log的数量：该命令结果中的`History list length`表示了undo log的数量。

### undo log 格式

在InnoDB 中，undo log分为：

* insert undo log：是insert操作中产生的undo log。因为insert操作的记录只对当前事务本身可见，对其他事务不可见。所以该undo log可以在事务提交后直接删除，不需要purge操作。
* update undo log：是对delete 和update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能再事务提交时就进行删除。提交时放入undo log 链表，等待purge线程进行最后的删除。

insert undo log格式如下：

![InsertUndoLogStructure](https://gitee.com/wangziming707/note-pic/raw/master/img/InsertUndoLogStructure.png)

其中`*`表示对存储的字段进行了压缩。 

* next占两个字节，记录的是下一个undo log的位置，通过该next字节可以知道一个undo log所占的空间字节数
* 尾部的start也占两个字节，记录的是undo log的开始位置
* type_cmpl占用一个字节，记录的是undo的类型，对于insert undo log，该值为11
* undo_no记录事务的ID
* table_id记录undo log所对应的表对象

update undo log结构如下：

![UpdateUndoLogStructure](https://gitee.com/wangziming707/note-pic/raw/master/img/UpdateUndoLogStructure.png)

update undo log的next、start、undo_no、table_id与insert undo log部分相同。

这里的type_cmpl在update undo log本身还有分类，可能的值：

* 12 trx_undo_upd_exist_rec 更新non-delete-mark的记录
* 13 trx_undo_upd_del_rec 将delete记录标记为not delete
* 14 trx_undo_del_mark_rec将记录标记为delete

接着的部分记录update_vector信息，表示update操作导致发生改变的列。

## purge

delete 和update操作可能并不直接删除原有的数据，而是仅仅将行记录中的`deleteted_flag`标志设置为1。真正的删除操作实在purge操作中完成的。

purge用于最终完成delete和update操作。这是因为InnoDB支持MVCC，所以记录不能在事务提交时立即进行处理。因此其他事务可能正在访问，所以InnoDB需要保存记录之前的版本。而是否可以删除这条记录通过purge来进行判断。若该行记录不再被任何其他事务引用，那么就可以进行真正的delete操作。

我们之前已经介绍过，为了节省存储空间，InnoDB设计了一个页上允许多个事务的undo log存在，并且在事务提交后，将undo log存放在一个history链表中，根据事务提交的顺序，将undo log进行链接。

在purge操作时同样会进行undo页的清理，首先会访问 history list中第一个事务的undo log ，清除它，并查找其所在页的其他undo log，看是否同样可以清除。接着继续访问history list中的第一个节点。这样可以避免大量的随机读取操作，从而提高purge效率。

全局动态参数`innodb_purge_batch_size`用来设置每次purge操作需要清理的undo page数量。默认值为300。

当InnoDB压力过大时，不能高效进行purge操作。那么history list的长度就会越来越长。全局动态参数`innodb_max_purge_lag`用来控制history list的长度，若长度大于该参数，其会延缓DML的操作，该参数默认值为0，表示不对history list做任何限制。当大于0时，会延缓DML的操作，其延缓的算法是：
$$
delay = (length(history\_list) - innodb\_max\_purge\_lag)*10 -5
$$
delay的单位是毫秒。另外，delay的对象是行，而不是DML操作。例如一个update操作需要更新5行数据时，每行数据的操作都会被delay，所以总延时5*delay。

全局动态参数`innodb_max_purge_lag_delay`控制delay的最大毫秒数。当上述计算的delay值大于该参数时，将delay设置为该值，避免purge操作缓慢导致SQL线程出现无限制的等待。

## group commit

若事务为非只读事务，且参数`innodb_flush_log_at_trx_commit`为默认值1，则每次事务提交时需要进行一次fsync操作，将重做日志从系统内存中刷入系统硬盘中。(虽然数据库向操作系统发出指令将数据存储到硬盘，但是操作系统为了性能考虑首先会将这些数据放入系统内存中，所以需要数据库提交一个fsync强制操作)

但是磁盘fsync性能是有限的。为了提高磁盘fsync的效率，数据库提供了group commit功能，即一次fsync可以刷新确保多个事务日志被写入文件。对InnoDB来说，事务提交时会进行两个阶段的操作：

* 修改内存中的事务对应的信息，并且将日志写入重做日志缓冲
* 调用fsync将确保日志都从重做日志缓冲写入磁盘

第二步是一个较慢的过程。所以当有多个事务进行这个过程中是，完成第一步的事务可以先等待，当多个事务都完成第一步时，将多个事务的重做日志通过一次fsync刷新到磁盘，这样就大大减少磁盘的IO压力，从而提高数据库的整体性能。

### 解决group commit失效

但是在InnoDB1.2版本之前，开启binlog后，group commit功能就会失效，这是因为数据库需要保证存储引擎层的事务和二进制日志的一致性，使用了两阶段事务，步骤如下：

1. 事务提交时InnoDB进行prepare操作

2. MySQL数据库上层写入二进制日志

3. InnoDB将日志写入重做日志文件：

   a. 修改内存中的事务对应的信息，并且将日志写入重做日志缓冲

   b. 调用fsync将确保日志都从重做日志缓冲写入磁盘

上面每个步骤都需要进行一次fsync操作才能确保上下两层数据的一致性。步骤2的fsync由`sync_binlog`控制，步骤3的fsync由参数`innodb_flush_log_at_trx_commit`

为了确保MySQL数据库上层二进制日志的写入顺序和InnoDB层的事务提交顺序一致(因为备份和回复的需要)，MySQL数据库内部使用了prepare_commit_mutex锁。但是启用这个锁喉，步骤a就不可以在其他事务执行步骤b时进行，从而导致了group commit 失效。

MySQL5.6通过Binary Log Group Commit(BLGC)的方式解决了group commit失效的问题

BLGC通过将事务提交的过程称为几个步骤来完成，如图：

![BLGC](https://gitee.com/wangziming707/note-pic/raw/master/img/BLGC.png)

在MySQL数据库上层进行提交时首先按顺序将其放入一个队列中。队列中的第一个事务称为leader，其他事务称为follower，leader控制着follower的行为。BLGC的步骤分为以下三个阶段：

* Flush阶段，将每个事务的二进制日志写入内存中
* Sync阶段，将内存中的二进制日志刷新到磁盘，若队列中有多个事务，那么仅一次fsync操作就完成了二进制日志的写入
* Commit阶段，leader根据顺序调用存储引擎层事务的提交，在这个阶段，取消了prepare_commit_mutex锁，所以就能恢复group commit

当有一组事务在进行Commit阶段时，其他新事务可以进行Flush阶段，从而使group commit不断生效。

参数`binlog_max_flush_queue_time`用来控制Flush阶段中等待的时间，即使之前一组事务完成提交，当前一组的事务也不马上进入Sync阶段，而是至少等待一段时间。这样做的好处是group commit的事务数量更多，但是也会导致事务的响应时间变慢。该参数的默认值为0，且推荐值也为0.除非用户的MySQL数据库系统中有着大量的连接，并且不在进行事务的写入和更新操作。

# 事务控制语句

在MySQL命令行的默认设置下，事务都是自动提交的，执行SQL语句后就会马上执行commit操作。要显示地开启一个事务需要使用命令 `begin`、`start transaction`或执行命令`set autocommit=0`,禁用当前会话的自动提交。

我们可以使用下面事务控制语句：

* `start transaction | begin`：显示地开启一个事务
* `commit`提交事务，或者使用`commit work`
* `rollback`：回滚当前事务，撤销未提交的修改;或者使用`rollback work`
* `savepoint identifier`:创建一个保存点
* `release savepoint identifier`:删除一个保存点
* `rollback to [savepoint] identifier`：将事务回滚到指定保存点
* `set transaction`设置事务的隔离级别。InnoDB提供4中隔离级别：
  * read uncommitted
  * read committed
  * repeatable read
  * serializable

`commit`和`commit work`基本一致，但是`commit work`可以用来控制事务结束后的行为是chain还是release的。如果是chain，那么事务就变成链事务。

可以通过参数`completion_type`来控制，有如下参数值：

* 0，默认值，表示`commit work`和`commit`完全等价，没有任何区别。
* 1，表示`commit work`等同于`commit and chain`表示马上自动开启一个相同隔离级别的事务
* 2，表示`commit work`等同于`commit and release`。在事务提交后自动断开与服务器的连接

`rollback work`和`commit work`的行为类似，不在赘述。

## 隐式提交的SQL语句

下面SQL语句会产生一个隐式的提交操作，即commit操作：

* DDL语句：如alter table，alter view ，drop table，等
* 用来隐式修改MySQL架构的操作：create user 、drop user、grant 、rename user、revoke、set password
* 管理语句：analyze table、cache index 、check table、 load index into cache、optimize table、repaire table

## 对事务操作的统计

InnoDB除了需要关注每秒请求数(Question Per Second,QPS),还应该关注每秒事务处理的能力(Transaction Per Second,TPS)

计算TPS的方法是(com_commit +com_rollback)/time。使用这个公式的前提是所有事务必须显示提交，因此隐式的提交和回滚不会计算到com_commit, com_rollback变量中

可以通过命令`show global status like 'com_commit'`来查看这两个值

# 事务隔离级别

SQL标准定义的四个隔离级别是：

* read uncommitted
* read committed
* repeatable read
* serializable

InnoDB默认的隔离级别是repeatable read，与SQL标准不同的是，InnoDB在repeatable read下使用了Next-Key Lock的算法，避免了幻读。所以可以说InnoDB 的repeatable read事务隔离级别下就完全保证事务的隔离性要求，即达到了SQL标准的serializable隔离级别。

一般来说，隔离级别越低，事务请求的锁越少，或者持有锁的时间越短，性能越高。但是事实上高隔离级别并不会带来明显的性能损失。

在InnoDB中，可以使用下面命令来设置当前会话或全局的事务隔离级别：

~~~mysql
set [global | session] transaction isolation level
{
 read uncommitted |
 read committed |
 repeatable read |
 serializable 
}
~~~

要永远修改数据库的个隔离级别，需要修改MySQL配置文件，在`[mysql]`中添加如下行：

~~~mysql
[mysql]
transaction-isolation = READ-COMMITTED
~~~

查看当前会话或者全局的事务隔离级别，可以使用：

~~~mysql
select @@tx_isolation;
select @@global.tx_isolation;
~~~

## serializable

InnoDB在serializable隔离级别下

* 会对每个更新语句添加上互斥锁。

* 会对每个select语句后自动加上加上 lock in share mode，即为每个读取操作添加一个共享锁。因此此时不再支持非锁定读。

这样就实现了完全的事务串行化。

但是因为InnoDB在 repeatable read 下就完全实现了SQL标准的serializable级别。所以一般InnoDB不需要在本地事务中使用serializable隔离级别。serializable的隔离级别主要用于InnoDB的分布式事务。

## repeatable read





## read committed











