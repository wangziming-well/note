

# 串行、并发和并行

串行：按顺序依次完成任务，一个时刻只能有一个任务在执行中

并行：同时执行多个任务，一个时刻有多个任务在执行中

并发：以交替的方式利用等待任务所需资源的时间来完成其他任务，一个时刻只能有一个任务在执行中，但以时间段观察，像是在同时执行多个任务。

从硬件的角度来说，在一个处理器一次只能运行一个线程的情况下，由于处理器可以使用时间片分配技术来实现同一段时间内运行多个线程，因此一个处理器就可以实现并发。而并行需要靠多个处理器在同一时刻各自运行一个线程来实现。

多线程编程的实质就是将任务的处理方式由串行改为并发，即实现并发化，以发挥并发又是。

如果一个任务的处理方式可以由串行改为并发(或者并行)，那么我们就称这个任务是可并发化(或者可并行化)

# 竞态

一个计算结果的正确性与时间有关的现象被称为竞态(RaceCondition).即一个问题对相同的输入，程序的输出有时是正确的有时却是错误的

## 模拟竞态

设计一个单例的ID生成器；生成的ID由当前的时间戳和三位在000~999之间自然增长循环的后缀组成

~~~java
public class IDGenerator {

    private final static IDGenerator INSTANCE = new IDGenerator();
    private final static short SEQ_LIMIT = 999;
    private short sequence = -1;
    
    private short nextSeq() {
        if (sequence >= SEQ_LIMIT)
            sequence = 0;
        else
            sequence++;
        return sequence;
    }
    
    public String nextID() {
        SimpleDateFormat formatter = new SimpleDateFormat("yyMMddHHmmss");
        String timestamp = formatter.format(new Date());
        DecimalFormat df = new DecimalFormat("000");
        short sequenceNo = nextSeq();
        return timestamp + df.format(sequenceNo);
    }
    
    public static IDGenerator getInstance(){
        return INSTANCE;
    }
}
~~~

在单线程调用该生成器是，没有问题：

~~~java
IDGenerator idGenerator = IDGenerator.getInstance();
IDGenerator idGenerator = IDGenerator.getInstance();
for (int i = 0; i < 20; i++) {
    System.out.print(idGenerator.nextID()+";");
}
//230706091939000;230706091939001;230706091939002;230706091939003;230706091939004;230706091939005;230706091939006;230706091939007;230706091939008;230706091939009;230706091939010;230706091939011;230706091939012;230706091939013;230706091939014;230706091939015;230706091939016;230706091939017;230706091939018;230706091939019;
~~~

接下来我们用多线程模拟实际调用情况

首先创建一个使用生成器的工作者线程，一个工作者线程调用10次生成器；调用间隔随机：

~~~java
public class WorkerThread extends Thread {

    private static final Random random = new Random();
    @Override
    public void run() {
        IDGenerator idGenerator = IDGenerator.getInstance();
        for (int i = 0; i < 10; i++) {
            randomPause();
            System.out.println(getName()+" got ID:"+ idGenerator.nextID());
        }
    }
    private void randomPause(){
        try {
            Thread.sleep(random.nextInt(50));
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }
}
~~~

然后模拟4个工作线程；尽量同时启动

~~~java
//预先创建线程,然后再启动;这样保证尽量同时启动
Thread[] threads = new Thread[4];
for (int i = 0; i < 4; i++) {
    threads[i] = new WorkerThread("worker-"+ (i+1));
}
for (int i = 0; i <4; i++) {
    threads[i].start();
}
~~~

结果输出如下：

~~~java
worker-2 got ID:230706102408001
worker-1 got ID:230706102408001
worker-3 got ID:230706102408000
worker-1 got ID:230706102408002
···········
worker-4 got ID:230706102408037
worker-4 got ID:230706102408038
~~~

可以看到，本应该自然增长的最后三位出现了重复,并且40次调用最后应该输出的后缀预期是039，但实际最后的输出是038

`IDGenerator.nextID()`方法本应该每次调用都输出不同的ID；但是在这种情况下出现了两次调用的ID相同的现象。

## 竞态现象分析

以上面的demo为例，来分析多线程环境下出现竞态的原因：

因为是ID后缀出现重复，可以看出问题出在`nextSeq()`方法，`nextSeq()`的`sequence++`这一行代码代表着下面三个指令

①`load(sequence,r)`：将变量sequence的值从内存读到寄存器r

②`increment(r)`：将寄存器r的值增加1

③`store(sequence,r)`：将寄存器r的内容重新写入变量sequence所对应的内存空间

假设worker-1，worker-2使用的寄存器分别时r1,和r2

而示例的四个线程在执行以上三个指令时可能按照下面表格的顺序交错进行：

| 时刻  | worker-1                          | worker-2                          |
| ----- | --------------------------------- | --------------------------------- |
| $t_1$ | [sequence=0]，执行指令1，[r1=0]   | 其他操作                          |
| $t_2$ | [r1=0],执行指令2，[r1=1]          | [sequence=0]，执行指令1,[r2=0]    |
| $t_3$ | [r1=1]，执行指令3，[sequence = 1] | [r2=0],执行指令2，[r2=1]          |
| $t_4$ | nextID返回结果1                   | [r2=1]，执行指令3，[sequence = 1] |
| $t_5$ | 其他操作                          | nextID返回结果1                   |

按照这种顺序：在$t_2$时刻worker-1读取了sequence内存的数据但还未计算完成重写写回内存的时机，worker-2；执行了指令一，再次读取了sequence=0的数据。接下来$t_5$时刻worker-2执行指令3覆盖了worker-1写入的数据。按照这样的顺序；两个线程调用的`nextID()`方法都返回了1.

通过上面的分析。竞态往往是因为多线程环境下，一个线程读取了脏数据，即一个线程读取到一个过时的数据(对应worker-2在$t_2$时刻的操作)，和丢失更新的问题

### 竞态的两种模式

产生竞态的两种模式如下：

* read-modifyj-write(读-改-写)：在多线程环境下可能因为线程执行顺序而导致脏读，更新丢失
* check-then-act(检测后执行)：在多线程环境下可能一个线程检测后还未执行时，可能因为其他线程导致检测条件变动，此时原线程再执行检测后任务时已经不符合该任务的执行条件

# 线程安全性

如果一个类在单线程环境下能运作正常，并且在多线程环境下，在其使用方不做任何改变的情况下也能运行正常，那么我们就称其是线程安全的(Thread-safe)，相应地我们称这个类具有线程安全性(Thread Safety)

反之，如果一个类在单线程环境下运行正常而在多线程环境下无法正常运作，那么这个类就是非线程安全的

使用一个类是我们必须弄清楚这个类是否是线程安全的。Java标准库中的一些类HashMap、ArrayList和SimpleDateFormat都是非线程安全的，在多线程环境下直接使用可能会导致一些非预期的甚至是灾难性的结果。比如多线程环境下多个线程共享一个HashMap实例(不采取任何控制措施)可能会导致死循环和内存泄漏。

一个类需要是线程安全的和它预期的被使用的方式有关，如果希望一个类只能被一个线程单独使用，那么就没有必要将这个类设计成线程安全的。另外，把一个类线程安全的往往是有额外的代价的。

线程安全表现为三个方面：原子性、可见性和有序性

# 原子性

原子(Atomic)的字面意思是不可分割的(Indivisible)。对于涉及共享变量访问的操作，若该操作从其执行线程以外的任意线程来看是不可分割的，那么该操作就是原子操作，相应地我们称该操作具有原子性(Atomicity)

所谓“不可分割”的原子操作有两重含义：

* 其中一个含义是指访问(读写)某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经执行结束要么尚未方式，即其他线程不会“看到”该操作执行了部分的中间效果。

* 另外一个含义是访问同一组共享变量的原子操作是不能被交错的，假设O1和O2是访问共享变量V的两个原子操作，那么一个线程执行O1期间(开始执行而未执行完毕),其他线程无法执行O2.这就排除了一个线程执行操作期间另一个线程读取或者更新该操作所访问的共享变量而导致的干扰(脏读)和冲突(丢失更新)的可能。由此可见，使一个操作具备原子性也就消除了这个操作导致竞态的可能性。

另外：

* 原子操作是正对访问共享变量的操作而言的。也就是说，仅涉及局部变量访问的操作无所谓是否是原子的
* 原子操作是从该操作的执行线程以外的线程来描述的，也就是说它只有在多线程环境下有意义。

## 实现原子性

总的来说，Java中有两种方式来实现原子性：

* 一是使用锁(Lock)。锁具有排他性，即它能够保障要给共享变量在任意一个时刻只能被一个线程访问。这就消除了竞态
* 另一种是利用处理器提供的专门CAS(Compare and Swap)指令，CAS执行实现原子性的方式和锁实现原子性方式实质上是相同的，差别在于锁通常是在软件这一层次实现的，而CAS是直接在硬件(处理器和内存)这一层次实现的，它可以被看作“硬件锁”

## Java中的原子操作

在Java中，long和double类型以外的任何类型的变量的写操作都是原子操作，即对long和double以外的基础类型和任意引用类型的写操作都是原子的。这是由Java语言规范规定，由JVM具体实现的。

而long和double类型的非原子性是因为32位的操作系统单次操作能处理的最长长度为32bit；而long和double都是64bit的；所以对long和double的读写在32位操作系统中需要两条指令才能完成(先写低32位，再写高32位)

Java语言规范特别规定对于volatile关键字修饰的long/double型变量的写操作具有原子性：

~~~java
volatile long value;
~~~

Java中针对任何变量的读操作都是原子操作

# 可见性

如果一个线程对某个共享变量进行更新后，后续访问该变量的线程可以读取到该更新的结果，那么我们就称这个线程多该共享变量的更新对其他线程可见，否则我们就称这个线程对该共享变量的更新对其他线程不可见。

可见性就是指一个线程对共享变量的更新的结果对于读取相应共享变量的线程而言是否可见的问题。

一个可见性的Demo：

~~~java
public class VisibilityDemo {

    public static void main(String[] args) throws InterruptedException {
        Task task = new Task();
        Thread thread = new Thread(task);
        thread.start();
        Thread.sleep(1000);
        task.shutDown();
    }

    private static class Task implements Runnable {
        public int i = 0;
        public boolean isRunning = true;

        @Override
        public void run() {
            while(isRunning){
                i++;
            }
            System.out.println(i);
        }

        public void shutDown(){
            isRunning = false;
            System.out.println("shutDown");
        }
    }
}
~~~

当我们调用`Task.shutDown()`方法后，预期isRunning变为false；`run()`方法中的while循环结束，打印i后task对应的线程结束。但实际上启动该demo后程序没有如预期的那样，在1s后程序结束。所以判断子线程没有读取到main线程对isRunning变量的更新，仍然读取的旧值true。

## 可见性问题原因

### JIT编译器优化

==存疑存疑存疑存疑？？？？？？==

JIT编译器对编码有循环提升(Loop Hoisting)的优化：为了避免在循环中重复读取JIT认为不会改变的变量，它会将循环判断条件提到循环外进行，如:

~~~java
while(bValue){
    .......
}
~~~

编译后的机器码实际上执行的是如下逻辑：

~~~java
if(bValue){
    while(bValue){
        .......
    }
}
~~~

如果循环开始后变量bValue在当前线程中没有改变，而可能被其他线程改变；那么这种改变将不会被当前线程读取到，陷入了死循环。

### 多核处理器缓存

产生可见性问题与计算机的存储系统相关。因为处理器的处理速度和主内存的速度差距十分巨大，所以处理器往往不直接访问主内存，而是通过寄存器(Register)、高速缓存(Cache)、写缓冲器(Store Buffer)和无效化队列(Invalidate Queue)等部件执行内存的读写操作，以提高整体效率。为了方便描述，接下来我们将这个部件统一简称为处理器缓存。

#### 寄存器

程序中的变量可能被分配到寄存器而不是主内存中进行存储。多于多处理器系统，每个处理器都有对应的寄存器，一个处理器无法读取另一个处理器上的寄存器中的内容。所以如果两个线程分别运行在不同的处理器上，而这两个线程的共享变量被分配到了寄存器上进行存储。那么一个线程对共享变量的更新只有在当前处理器上的线程能访问，因为另一个线程在另外的cpu上，所以另外的线程无法访问到更新后的共享变量。就产生了可见性问题。

####  高速缓存系统

另外，即使某个共享变量被分配到寄存器上进行存储，也不能保证变量的可变性。

一个处理器上运行的线程对变量的更新可能只有更新到该处理器的写缓冲器中，还没有到达处理器的高速缓存区，更不用说主内存。而一个处理器的写缓冲器中的内容无法没另外一个处理器读取，因此此时一个处理器上运行的线程对共享变量的更新无法被另一个处理器上的线程读取。

即使该处理器将这个变量的更新结果被写入该处理器的高速缓存，由于该处理器将这个变量的结果通知给其他处理器时，其他处理器可能仅仅将这个更新通知的内容存入无效化队列中，而不是根据更新通知的内容更新其高速缓存的相应内容，此时仍然有可见性问题。

### 单核处理器上下文切换

多线程运行在单核处理器上也有可能出现可见性问题，因为发生上下文切换的时候，一个线程对寄存器变量的修改会被该线程的线程上下文保存起来，导致另外线程无法访问到该线程对这个变量的修改

## 可见性问题的解决方案

### 缓存一致性协议

虽然一个处理器的高速缓存中的内容不能被其他处理器直接读取，但是一个处理器可以通过缓存一致性协议(Cache Coherence Protocol)来读取其他处理器的高速缓存中的数据，并将读取到的数据更新到该处理器的高速缓存中。这个过程称为缓存同步，缓存同步使得一个处理器上的线程可以读取到另外一个处理器上的线程对共享变量的更新，即保障了可见性。

所以为了保障可见性，首先我们必须使一个处理器对共享变量所做的更新最终被写入该处理器的高速缓存或主内存中，而不是始终停留在写缓冲器中；这个将写缓存器中的数据最终写入高速缓存/主内存的过程被称为冲刷处理器缓存(flush cache)；然后一个处理器对共享变量的更新需要通过缓存同步写入其他处理器的高速缓存；这个过程被称为刷新处理器缓存(reflash cache)

所以处理器保障可见性是通过使更新共享变量的处理器执行冲刷处理器缓存并刷新处理器缓存的动作实现的。

### volatile保证可见性

使用volatile修饰变量，有如下作用：

* 提示JIT编译器被修饰的变量可能被多线程共享，以阻止JIT编译器做出可能导致程序异常的优化
* 读取一个volatile关键字修饰的变量之前会使相应的处理器执行刷新处理器缓存的动作
* 写入一个volatile关键字修饰的变量之后会使相应的处理器执行冲刷处理器缓存的动作

从而保证了可见性。所以在上面的demo中，我们只要用`volatile`修饰isRunning变量就能保证他的可见性，使程序得到预期的结果

## 即使保障了可见性

相对新值：对于同一个共享变量而言，一个线程更新了该变量的值之后，其他线程能够读取到这个更新后的值，那么这个值就被称为该变量的相对新值

最新值：如果读取这个共享变量的线程在读取并使用该变量的时候其他线程无法更新该变量的值，那么该线程读取到的相对新值就被称为该变量的最新值。

可见性仅能保障一个线程能够读到共享变量的相对新值，而不能保障该线程能读到相应变量的最新值。

## 线程的启动、停止与可见性

Java语言规范保证：

* 父线程在启动子线程之前对共享变量的更新对子线程来说是可见的
* 一个线程终止后该线程对共享变量的更新对于调用该线程的join方法的线程而言是可见的。

# 有序性

有序性(Ordering)指在什么情况下一个处理器上运行的线程所执行的内存访问操作在另一个处理器上运行的其他线程看起来是乱序的。乱序指内存访问操作的顺序看起来像是发生了变化。

为了方便 讨论，假定每个线程都运行在各自的处理器，即不考虑一个处理器上基于时间片分时实现的多线程

## 重排序

顺序结构是结构化编程中的一种基本结构，它表示我们希望某个操作必须先于另一个操作得以执行。两个操作总有先后顺序。

但是在多核处理器的环境下，这种操作执行顺序可能是没有保障的：编译器可能改变两个操作的先后顺序；处理器可能不是完全依照程序的目标代码所指定的顺序执行命令；一个处理器上执行的多个操作，从其他处理器的角度来看其顺序可能与目标代码所指定的顺序。这种现象就叫重排序。

重排序是对内存访问有关操作(读和写)所做的一种优化，它可以在不影响单线程程序正确性的情况下提升程序的性能。但是，它可能对多线程程序的正确性产生影响，即它可能导致线程安全问题。

重排序的潜在来源有许多，包括JIT编译器，处理器和存储子系统(包括写缓冲器、高速缓存)

需要定义几个与内存操作顺序有关的术语：

* 源代码顺序(Source Code Order):源代码中所执行的内存访问操作顺序

* 程序顺序(Program Order):在给定处理器上运行的目标代码所执行的内存访问操作顺序

  尽管Java虚拟机执行Java代码有两种方式：解释执行(被执行的是字节码)和编译执行(被执行的是机器码)。为了便于讨论，这里仅将目标代码定义位字节码

* 执行顺序(Execution Order):内存访问操作在给定处理器上的时机执行顺序

* 感知顺序(Perceived Order):给定处理器所感知到/看到的该处理器及其他处理器的内存访问操作发生的顺序。

在此基础上，将重排序细分为指令重排序和存储子系统重排序，如表：

<table>
  <tr>
    <th>重排序类型</th>
    <th>重排序表现</th>
    <th>重排序来源(主题)</th>
  </tr>
  <tr>
    <td rowspan="2">指令重排序</td>
    <td>程序顺序与源代码顺序不一致</td>
    <td>编译器</td>
  </tr>
  <tr>
    <td>执行顺序与程序顺序不一致</td>
    <td>JIT编译器、处理器</td>
  </tr>
  <tr>
    <td>存储子系统重排序</td>
    <td>源代码顺序、程序顺序、执行顺序三者保持一致，<br>但感知顺序与执行顺序不一致</td>
    <td>高速缓存、写缓冲器</td>
  </tr>
</table>

### 指令重排序

在源代码顺序和程序顺序不一致，或者程序顺序与执行顺序不一致的情况下，我们就说发生了指令重排序。

####  编译器优化

Java平台包含两种编译器：

* 静态编译器(javac):将Java源代码(.java)编译为字节码(.class)，它是在代码编译阶段介入的。
* 动态编译器(JIT编译器)：将字节码动态编译为Java虚拟机宿主机的本地代码(机器码),它是在Java程序运行过程中介入的。

编译器处于性能考虑，在其认为不影响程序(单线程程序)正确性的情况下可能会对源代码顺序进行调整，造成程序顺序与源代码顺序不一致。静态编译器基本上不会执行指令重排序，而JIT编译器则可能执行执行重排序。

以下代码演示JIT重排序：

~~~java
public class JitReorderDemo {
    public static void main(String[] args) {
        while (true) {
            Stat stat = new Stat();
            Thread writeThread = new Thread(() -> 
                {stat.a = 1;stat.b = 1;stat.c = 1;stat.d = 1;});
            Thread readThread =new Thread(() -> 
                {int a = stat.a;int b = stat.b;int c = stat.c;int d =stat.d;
                if (a == 0 && (b+c+d)!=0){
                    System.out.printf("(a,b,c,d)=(%s,%s,%s,%s)\n",a,b,c,d);
                }
            });
            writeThread.start();
            readThread.start();
        }
    }
    static class Stat {
        int a = 0;int b = 0;int c = 0;int d = 0;
    }
}
~~~

类Stat有四个变量a,b,c,d；写线程依次为a,b,c,d赋值，而读线程读取Stat对象的a,b,c,d的值

如果按照代码定义的源代码顺序执行，当a=0时，b,c,d都应该为0；因为写线程中代码执行顺序是按照a,b,c,d依次赋值。所以按照这种分析，if分支下的打印语句是不会被触发的。但是实际上运行该Demo一段时间，就可能有输出：

~~~java
(a,b,c,d)=(0,1,1,1)
(a,b,c,d)=(0,1,1,1)
(a,b,c,d)=(0,0,1,0)
~~~

说明执行顺序并不是按照程序顺序；JIT对机器码进行了指令重排序

#### 处理器乱序执行

处理器也可能执行指令重排序，这使得执行顺序和程序顺序不一致。处理器对指令进行重排序也被称为处理器的乱序执行。现代处理器为了提高指令执行效率，往往不是按照程序顺序逐一执行命令的，而是动态调整指令的顺序，做到哪条指令就绪就先执行哪条指令。

在乱序执行的处理器中，指令是一条一条按照顺序被处理器读取的(顺序读取),然后这些指令中哪条就绪了哪条就会被执行，而不是完全按照程序顺序执行(即乱序执行).这些指令的执行的结果会被先存入重排序缓冲器(ROB,Reorder Buffer)，而不是直接被吸入寄存器或者主内存。重排序缓冲器会将各个指令的执行结果按照相应指令被处理器读取的顺序提交到寄存器或者内存中去(顺序提交).在乱序执行的情况下，尽管指令的执行顺序没有完全按照程序顺序，但是由于执行的执行结果的提交(即反映到寄存器和内存中)仍然是按照程序顺序来的，因此处理器的指令重排序并不会对单线程程序的正确性造成影响。

~~~java
public class ReorderingDemo {
    static int x = 0, y = 0;
    static int a = 0, b = 0;

    public static void main(String[] args) throws InterruptedException {
        while (true) {
            reSort();
        }
    }
    static void reSort() throws InterruptedException {
        Thread t1 = new Thread(() -> {
            a = 1; //操作1
            x = b; //操作2
        });
        Thread t2= new Thread(() -> {
            b = 1; //操作3
            y = a;  //操作4
        });
        t1.start();
        t2.start();
        t1.join();
        t2.join();
        if (x == 0 && y ==0){
            System.out.println("(" + x + "," + y + ")");
        }
        x = 0;y = 0;a = 0;b = 0;
    }
}
~~~

两个线程t1,t2各自对四个变量a,b,x,y进行一次更新，如果更新后x,y都为0，则输出结果；

我们先分析一些，以上代码预期的输出：对变量执行的操作1，2，3，4；按照源代码顺序，操作1一定在操作2之前，操作3一定在操作4之前；那么这四个操作只可能是以下顺序：

* 1,2,3,4 ->(0,1)
* 1,3,2,4->(1,1)
* 1,3,4,2->(1,1)
* 3,4,1,2->(1,0)
* 3,1,4,2->(1.1)
* 3,4,1,2->(1,1)

可以看出只要按照1在2之前，3在4之前的次序；那么这个程序是永远不会有输出的，但经过一段时间的运行后，我们确可能看到程序输出了(0,0);那么可以推断代码经过了指令重排序，使操作2在操作1之前，或者操作4在操作3之前了。

#### 处理器预测执行

处理器的乱序执行还采用了一种被称为分支猜测/预测执行(Speculation)的技术。猜测执行技术能够造成if语句的语句体先于其条件语句被执行的结果，即可能导致指令重排序；

cpu可能先执行if语句的语句体；将语句体的执行结果缓存到重排序缓冲器中

如果if语句的条件语句为true，将重排序缓冲器中的语句体执行结果写入主内存或高速缓存中；

如果if语句的条件语句为false，则丢弃重排序缓冲器中的语句体执行结果

在多线程环境下这可能导致线程安全问题

### 存储子系统重排序

之前已经提到，主内存相对于处理器是一个慢速设备。为了避免内存称为性能瓶颈，处理器并不是直接访问主内存，而是通过高速缓存(Cache)访问主内存。在此基础上，还引入了写缓冲器以提高高速缓存操作的效率。我们将写缓冲器和高速缓存称为存储子系统，它其实是处理器的子系统。

即使在处理器严格依照程序顺序执行两个内存访问操作的情况下，在存储子系统的作用下其他处理器对这两个操作的感知顺序仍然可能和程序顺序不一致，即这两个操作的执行顺序看起来好像是发生了变化。这种现象就是存储子系统重排序，也被称为内存重排序。

指令重排序的重排序对象是指令，它实实在在地对指令的顺序进行调整，而存储子系统重排序是一种现象而不是一种动作，它并没有真正地对指令顺序执行进行调整，而只是造成了一种指令的执行顺序像是被调整过一样的现象，其重排序的对象是内存操作的结果。

从处理器的角度来说，读内存操作的实质时从指定的主内存地址加载数据(通过高速缓存加载)到寄存器，写内存操作的实质是将数据存储到指定地址表示的主内存中。

一些处理器的写缓冲器为了提高其中内容写入高速缓存的效率，而不保证写操作结果先入先出(FIFO)的顺序，即较晚到达写缓冲器的写操作结果可能更早地被写入高速缓存，这就导致在其他处理器看来，两个写操作进行了重排序，即使他们的执行顺序是顺序的。

## 貌似串行语句

通过对重排序的学习，我们发现重排序并非随意地对指令、内存操作的结果进行无序的调整，而是通过一定的规则，保证了单线程程序结果的正确性。即造成了一种假象：指令是按照源代码顺序执行的。这种假象就被称为貌似串行语义(As-if-serial Semantics)。貌似串行语义只是从单线程程序的角度保证重排序后的运行结果不影响程序的正确性，它并不保证多线程环境下程序的正确性

为了保证貌似串行语义，存在数据依赖关系的语句不会被重排序，只有不存在数据依赖关系的语句才会被重排序。如果两个指令访问同一地址，且其中一个指令为写，那么这两个操作之间就存在数据依赖关系，这包括：写后读，读后写，写后写

## 保证内存访问的顺序性

重排序会导致线程安全问题，为了避免这个问题，我们需要保证感知顺序与源代码顺序一致，即有序性

我们知道貌似串行语义只是保障重排序不影响单线程程序的正确性。从这个角度出发，有序性的保障可以理解为通过某些措施使得貌似串行语义扩展到多线程程序，即重排序要么不发生，要么即使发生也不会影响多线程程序的正确性。因此，有序性的保障也可以理解为从逻辑上部分禁止重排序。

从底层的角度来说，禁止重排序是通过调用处理器提供相应的指令(内存屏障)来实现的。Java本身提供的机制能替我们和底层指令打交道以实现有序性。`volatile`和`synchronized`关键字都能实现有序性

# 上下文切换

上下文切换(Context Switch)在某种程度上可以被看做多个线程共享一个处理器的产物，它是多线程编程中的一个重要概念

## 单核实现多线程原理

在单处理器上也能以多线程的方式实现并发，即一个处理器可以在同一时间段内运行多个线程。这是通过时间片分配的方式实现的。时间片就是一个线程可以连续占用处理器资源的时间长度。当一个进程中的一个线程由于其时间片用完或者其自身的原因被迫或主动暂停其运动时，另外一个线程(可能是同一个进程或者其他进程中的线程)可以被操作系统(线程调度器)选中占用处理器开始或者继续运行。

这种一个线程被暂停，即被剥夺处理器的使用权，另外一个先从被选中开始或者继续运行的过程就叫做线程上下文切换。简称上下文切换。

相应地，一个线程被剥夺处理器的使用权而被暂停运行就被称为切除(Switch Out)；一个线程被操作系统选中占用处理器开始或者继续其运行就被称为切入(Switch In)

可见从我们的视角看起来是连续运行的线程，实际上是以断断续续运行的方式完成任务的。这种方式意味着在切出切入的时候操作系统需要保存和恢复相应线程的进度信息，即切入和切出的那一刻相应线程所执行的任务进行到了什么程度(如计算的中间结果以及执行到了哪条指令)。这个进度信息就被称为上下文。它一般包括通用寄存器和程序计数器的内容。在切出时，操作系统需要将上下文保存到内存中，以便被切出的线程稍后占用处理器继续运行时能在此基础上进展。在切入时，操作系统需要从内存中加载(恢复)被选中线程的上下文，以在此以前运行的基础上继续运行。

从Java应用的角度来看，一个线程的生命凑齐在RUNNABLE状态和非RUNNABLE状态之间切换的过程就是一个上下文切换的过程。

* 线程暂停：当一个线程状态由RUNNABLE转换为非RUNNABLE时
* 线程唤醒：当一个线程状态由非RUNNABLE转换为RUNNABLE时

一个线程被唤醒仅代表线程获得了一个继续运行的机会，即处于READY状态，并不代表其立刻可以占用处理器运行。当处于READY状态的线程被处理器选中时，操作系统会恢复之前为该线程保存的上下文，在此基础上继续运行，即处于RUNNING状态。

## 上下文切换的开销和测量

上下文切换时必要的，即使是在多核处理器系统中，因为系统上需要运行的线程数量远远比系统拥有的核心数量大得多。但是上下文切换又有很大的开销

上下文切换的开销包括直接开销和间接开销：

* 直接开销：
  * 操作系统保存和恢复上下文所需的开销，这主要是处理器时间开销
  * 线程调度器进行线程调度的开销(比如，按照一定的算法决定哪个线程会占用处理器运行)
* 间接开销：
  * 处理器高速缓存重新加载的开销。一个被切出的线程可能稍后在另一个处理器上被切入继续运行。由于这个处理器之前可能未运行过该线程，那么这个线程在继续运行过程中需访问的变量仍然需要被该处理器重新从主内存或者通过缓存一致性协议从其他处理器加载到高速缓存中。需要一定的时间消耗
  * 上下文切换可能导致整个一级高速缓存中的内容被冲刷，即一级高速缓存中的内容会被写入下一级高速缓存或者主内存中。

从定量的角度来说，一次上下文切换的时间消耗是微妙级的。

线程数量越多，每个线程平均的上下文切换的开销可能越大。因此多线程编程中使用的线程数量越多，程序的计算效率可能反而越低。

对于不同的平台，可以使用对应的手段监控发生的上下文切换(主要是自发性上下文切换)的次数。

* Linux平台：使用perf命令
* Windows平台：使用perfmon工具

# 线程的活性故障

理想状态下我们希望线程一直处于RUNNABLE状态，但是情况不总是如我们所希望的那样，除了资源限制(处理器资源有限导致的上下文切换)外，还有程序自身的错误和限制。

由于资源稀缺性或者程序自身的问题和缺陷导致线程一直处于非RUNNABLE状态，或则和线程虽然处于RUNNABLE状态但是要执行的任务缺一直无法进展的现象就被称为线程活性故障，常见的活性故障包括以下几种：

* 死锁
* 锁死
* 活锁
* 饥饿

这些故障将在后续笔记中详细介绍

# 资源争用和调度

由于资源的稀缺性和资源本身的特性(如打印机一次只能打印一个文件)，我们往往需要在多个线程间共享一个资源。这会导致资源的争用，需要使用合适的调度策略来安排资源

## 排他性资源和资源争用

一次只能被一个线程占用的资源被称为排他性资源。常见的排他性资源包括处理器、数据库连接、文件等。

在一个线程占用一个排他性资源进行访问而未释放其对资源所有权的时候，其他线程试图访问该资源的现象被称为资源争用，简称争用。

同时试图访问同一个已经被其他线程占用的资源的线程数量越多，争用的程度就越高；反正争用的程度就越低。相应的争用就被称为高争用和低争用。

## 并发程度和争用

同一时间内，处于运行状态的线程数量越多，并发的程度越高，简称高并发。与之相对的是低并发。

虽然高并发增加了争用的概率，但高并发并非意味着高争用。如果线程对一个排他性资源的使用效率足够高；并且线程用这个排他性资源干的事情足够简单，耗时低；那么就可以做到在高并发的同时低争用。

## 资源调度

多个线程共享同一个资源又会带来资源的调度问题。

在多个线程申请同一个排他性资源的情况下，决定哪个资源会被授予该资源的独占权，即选择哪个申请者占用该资源的过程就是资源的调度。

资源调度策略按照是否公平可以分为以下两类：

* 公平调度策略：资源的申请者能够按照申请资源的顺序依次获得资源的独占权。资源的任何一个先申请者总是能比任何一个后申请者先获得该资源的独占权
  * 优点：吞吐率打
  * 缺点：资源申请者申请资源所需的时间偏差可能较大，可能导致饥饿现象
* 非公平调度策略：资源的一个后申请者可能插队比先申请者提前获取资源的独占权。非公平调度是指它允许不公平的资源调度出现，而不是表示它可以制造不公平的资源调度。
  * 优点：线程申请资源所需的时间偏差较小，不会导致饥饿现象
  * 缺点 是吞吐率小

在没有特别需要的情况下，默认选择非公平资源调度。





