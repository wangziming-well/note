# 内部锁优化

自Java6/Java7开始，JVM对内部锁的实现进行了一些优化。这些优化包括：锁消除、锁粗化、偏向锁以及适应性锁

这些优化仅在JVM server模式下起作用

## 锁消除

锁消除(Lock Elision)是JIT编译器对内部锁的具体实现所做的一种优化。

在动态编译同步块的时候，JIT编译器会借助一种被称为逃逸分析(Escape Analysis)的技术来判断同步块所使用的锁对象是否只能被一个线程访问而没有被发布到其他线程。

如果同步块所使用的锁对象通过这种分析被证实只能够被一个线程访问，那么JTI编译器在编译这个同步块时就不会生成synchronized锁表示的锁的申请和释放对应的机器码。

这样动态编译的字节码就像不包含monitorenter 和monitorexit这两个字节码一样，即消除了锁的使用。这种编译器优化就被称为锁消除。它使得在特定情况下可以完全避免锁的开销。

Java标准库中有许多类虽然是线程安全的，但在实际使用时我们往往不在多个线程间共享这些类的实例。而这些类实现线程安全的时候往往借助于内部锁。因此，这些类是锁消除优化的常见目标。如下面代码：

~~~java
public static String getInfo(User user){
    StringBuffer sbf = new StringBuffer();
    sbf.append("id:").append(user.id)
        .append(",name:").append(user.name)
        .append(",password:").append(user.password);
    return sbf.toString();
}
~~~

JIT编译器在编译`getInfo`方法的时候会将其调用的`StringBuffer.append()/toString()`方法内联到该方法之中，即相当于把`StringBuffer.append()/toString()`方法的方法体中的指令复制到了`getInfo()`方法之中。

这里`StringBuffer`的实例`sbf`是一个局部变量，并且没有被发布到其他线程，所以JIT编译器此时可以消除`getInfo()`方法中从`StringBuffer.append()/toString()`的方法体复制的指令所使用的内部锁。

在这个例子中`StringBuffer.append()/toString()`方法本身所使用的锁并不会被消除，因为系统中可能还有其他地方在使用StringBuffer，而这些代码的实例可能会共享StringBuffer实例。

从上述例子可以看出，锁消除优化可能需要以JIT编译器的内联优化为前提。而一个方法是否会被JIT编译器内联取决于该方法的热度以及该方法对应的字节码的尺寸。因此，锁消除优化能否被实施还取决于被调用的同步方法是否能够被内联

锁消除是JIT编译器而不是javac所做的一种优化，而一段代码只有在其执行的频率足够大的情况下才有可能被JIT编译器优化。也就是说在JIT编译器优化介入之前，只要源代码中使用了内部锁，那么这个锁的开销就会存在。

在锁消除的作用下，利用ThreadLocal将一个线程安全的对象(比如Random)做为一个线程特有对象来使用，不仅可以避免锁的争用，还可以彻底消除这些多想内部所使用的锁的开销。

## 锁粗化

锁粗化(Lock Coarsening/Lock Merging)是JIT编译器对内部锁的具体实现所做的一种优化。

对于相邻的几个同步块，如果这些同步块使用的是同一个锁实例，那么JIT编译器会将这些同步块合并为一个大同步块，从而避免一个线程反复申请、释放同一个锁所导致的开销。

然而锁粗化可能导致一个线程持有一个锁的时间变长，从而使得同步在该锁之上的其他线程在申请锁时的等待时间边长。因此锁粗化不会应用到循环体内的相邻同步代码。

锁粗化常常应用于连续调用同一个实例的同步方法的场景，如下例：

~~~java
public class LockMerging {
    private final Random rand = new Random();
    public void work() {
        double i = rand.nextGaussian();
        double j = rand.nextGaussian();
        double l = rand.nextGaussian();
    }
}
~~~

如果work()方法调用的足够频繁，那么JIT编译器可能将`nextGaussian()`方法内联到work()方法上。此时内联到`work()`方法中的代码相当于由`rand`引导的同步代码块。经过内联优化后，`work()`方法内就相当于有3个由rand引导的同步代码块。那么JIT编译器就可能进行锁的粗化，将三个同步代码块合并为一个。

## 偏向锁

偏向锁(Biased Locking)是JVM对锁的实现的一种优化

JVM在实现monitorenter字节码和monitorexit字节码时时需要借助一个原子操作(CAS操作)，这个操作代价相对来说比较昂贵。

因此JVM会为每个对象维护一个偏好(Bias)，即一个对象对应的内部锁第一次被一个线程获得，那么这个线程就会被记录为该对象的偏好线程。这个线程后续无论时再次申请锁还是释放锁，都无需借助原先的原子操作，从而减少了锁的申请和释放的开销。

然而，一个对象的偏好线程以外的其他先申请该对象的内部锁时，JVM需要回收该对象对原偏好线程的偏好，并重新设置该对象的偏好线程。这个偏好回收和重新分配过程的代价也是比较昂贵的。

所以，如果一个Java程序中的大多数锁都存在锁争用的情况，这种偏好回收和重新分配的代价将会被放大。

所以，偏向锁只适合存在相当大一部分锁并没有被争用的系统之中。如果系统中存在大量被争用的锁，而没被争用的锁占比较小，那么可以考虑关闭偏向锁优化。

## 适应性锁

适应性锁(Adaptive Locking)是JIT对内部锁实现所做的优化。

存在锁争用的情况下，一个线程申请一个锁的时候如果这个锁正在被其他线程持有，那么这个线程就需要等待该锁被其他持有线程释放。实现这种等待通常由下面两种方法：

* 将这个线程暂停，这会导致上下文切换
* 忙等：反复执行空操作直到所需的条件成立；缺点是比较耗费处理器资源，如果长时间没有等到锁释放，那么忙等的循环会被一直执行。

所以对于一个具体的锁实例来说，忙等策略比较适合大部分线程对该锁的持有时间比较短的场景，如果持有时间相对长，那么暂停线程策略会更合适。

事实上，JVM并非是只在两种策略中择其一，它可以综合使用上述两种策略。对于一个具体的锁实例，JVM会根据其运行时收集到的信息来判断这个锁是属于被线程持有时间较长还是较短的。如果被线程持有时间较长的锁，JVM会选择暂停等待策略；对于被线程持有时间较短的锁，JVM会选择忙等策略。JVM也可能先采取忙等策略，在忙等失败的情况下再采取暂停等待策略。这种优化就是适应性锁。也需要JIT编译器的介入。

# 优化锁的使用

## 锁的开销

锁的开销包括以下几个方面：

* 上下文切换和线程调度的开销：一个线程请求锁失败后，这个线程最终可能会被暂停。JVM还需要为这些被暂停的线程维护一个等待队列，以便这个锁在被释放的时候将这些线程唤醒。线程的暂停和唤醒会导致上下文切换，JVM维护等待队列也会产生一定的开销。

  非争用锁不会导致这样的开销

* 内存同步、编译器优化受限的开销：锁内部实现所使用的内存屏障也会产生直接和间接的开销：直接的开销时内存屏障所导致的冲刷写缓冲器、清空无效化队列所导致的开销。间接的开销是内存屏障会阻止JIT编译器的优化。

  无论是争用锁还是非争用锁，都会导致这部分开销。除非该锁经过了JIT编译器锁消除的优化。

* 限制可伸缩性：锁的排他性将局部的并发计算改为串行计算。这可能导致处理器资源或者其他资源的浪费，并限制系统的吞吐率。

可见，锁的开销主要体现在争用锁上面。因此，减少锁的开销的一个基本思路就是消除锁的使用(使用锁的替代品)或者降低锁的争用程度。

影响锁的争用程度的因素有两个：程序申请锁的频率以及锁通常被持有的时间跨度。程序越是频繁地申请一个锁，或者这个锁通常被持有线程持有的时间越长，那么这个锁的争用程度就越高；反之该锁的争用程度就越低。

因此，降低锁的争用程度的基本思路就是减少锁被持有的时间和减低锁的申请频率。

## 可参数化锁

如果一个方法或者类内部锁使用的锁实例可以由该方法、类的客户端代码指定，那么这个锁就是可参数化的，这个锁就被称为可参数化锁。

可参数化锁在特定的情况下有助于减少线程执行过程中参与的锁实例的个数，从而减少锁的开销。

如果锁不可参数化，只能由类、方法内部自己指定；那么大概率是一个类实例使用一个锁；但是如果锁是可参数化的，那么客户端在使用这样的类、方法时就可以让多个类实例使用同一个锁。

## 减小临界区的长度

减小临界区的长度可以减少锁被持有的时间从而减低锁被争用的概率，这有利于减少锁的开下。

另外，减少锁的持有时间有利于JVM的适应性锁优化发挥作用：在多个线程持有锁的时间都很短的情况下，锁的申请线程可以通过忙等而无需通过暂停线程来等待被争用的锁的释放。这有利于减少上下文切换开销。

临界区上的操作一般可以划分为：预处理操作、共享变量访问操作、后处理操作

其中预处理和后处理操作一般不涉及共享变量的访问，因此如果把这两种操作挪到临界区外可以在不导致线程安全问题的前提下减小临界区的长度。

如果预处理、后处理操作中涉及I/O操作、阻塞操作等比较耗时的操作，那么将这些操作挪到临界区外可以有效地减少锁被持有的时间。

## 减小锁的粒度

减小锁的粒度可以降低锁的申请频率，从而减小锁被争用的概率。

## 锁拆分

减小锁的粒度的一种常见方法是将一个粒度较粗的锁拆分成若干粒度更细的锁，其中每个锁仅负责保护原粗粒度锁所保护的所有共享变量中的一部分共享变量。这被称为锁拆分技术。

如果一个锁L保护了多个共享变量，如A,B,C;其中A仅由T1类线程访问；B、C仅由T2类线程访问；这种情况造成了不必要的锁竞争，T1类线程和T2类线程之间没有共享变量，但是仍然要竞争同一把锁。

我们可以将锁L拆分成L1和L2，其中L1保护A，L2保护B,C；这样就避免了T1类线程和T2类线程之间不必要的资源竞争。

一个锁保护多个由不同类线程访问的共享变量的场景，常出现一个类中使用了多个同步方法，因为同步方法使用的锁为类实例本身，所以实际上这些同步方法使用的是同一个锁，即一个锁保护了这些同步方法访问的所有共享变量。但是很有可能设计上这些共享变量之间有的并没有逻辑上的联系，这样就可以进行锁的拆分，用粒度更细的锁。

对于高争用的锁，锁拆分带来的效果可能并不是那么明显。可能会由一个高争用的锁变为两个高争用的锁。

### 锁分段

锁拆分这种技术可以演进为锁分段技术。锁分段是指对同一个数据结构内不同部分的数据使用个不同锁实例进行加锁的技术。

`ConcurrentHashMap`内部就是用了分段锁

## 不使用锁

在条件允许的情况下，我们也可以考虑使用锁的替代品来避免锁的开销和问题。

这些由条件的替代品包括：`volatile`关键字、原子变量、无状态对象、不可变对象和线程特有对象
